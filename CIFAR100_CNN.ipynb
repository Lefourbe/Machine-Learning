{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR100 CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO0ILTr9BuiuTZWldStMNGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentDufour/Machine-Learning/blob/master/CIFAR100_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ci7m777XR42",
        "colab_type": "text"
      },
      "source": [
        "<h1> Classification</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQYyIrPQQunu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f14d3ea0-5924-4b81-e597-3c4a2b102a33"
      },
      "source": [
        "import sys\n",
        "import sklearn\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "if not tf.test.is_gpu_available():\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2#for resieing images from 32*32 to 224*224\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "WARNING:tensorflow:From <ipython-input-1-cf088c276792>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_kq3HjQQ2tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def plot_color_image(image):\n",
        "    plt.imshow(image, interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpyxrvVNQ-LO",
        "colab_type": "code",
        "outputId": "0d016bf9-fbcb-44a2-d9b0-876fba154bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "n_classes = 100\n",
        "\n",
        "(X_train_full, y_train_full), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "#(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train, X_val = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_val = y_train_full[:-5000], y_train_full[-5000:]\n",
        "# StandardiZation\n",
        "X_mean = X_train.mean(axis=0, keepdims=True)\n",
        "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
        "X_train = (X_train - X_mean) / X_std\n",
        "X_val = (X_val - X_mean) / X_std\n",
        "X_test = (X_test - X_mean) / X_std\n",
        "print(\"X_train:\", type(X_train), X_train.shape, \"y_train\", type(y_train), y_train.shape)\n",
        "print(\"X_test:\", X_test.shape, \"  y_test:\", y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_train: <class 'numpy.ndarray'> (45000, 32, 32, 3) y_train <class 'numpy.ndarray'> (45000, 1)\n",
            "X_test: (10000, 32, 32, 3)   y_test: (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0A_KIMxSCPu",
        "colab_type": "code",
        "outputId": "007b9a34-5331-49fb-a901-291fcbce6ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "index = 0\n",
        "for image, label in zip(X_train[:9], y_train[:9]):\n",
        "    index += 1\n",
        "    plt.subplot(3, 3, index)\n",
        "    plot_color_image(np.squeeze(image))\n",
        "    plt.title(\"Class: {}\".format(label))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoYAAAI+CAYAAAAhE8thAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_dLFMjwXZSK",
        "colab_type": "text"
      },
      "source": [
        "<h2> Homemade CNN</h2>\n",
        "No need batch normalization because the network is not deep so we are not realy concerned by gradient instability. I applied dropout after each convolution layer wich is maybe not very conventional for convolution network (so poetic) but it leads to better accuracy (drop out rates could be fine tuned). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiL49INtRAHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "model = keras.models.Sequential([\n",
        "    DefaultConv2D(filters=128, kernel_size=4, input_shape=[32, 32, 3]),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    DefaultConv2D(filters=128, strides=2),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    DefaultConv2D(filters=256),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    DefaultConv2D(filters=256),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    DefaultConv2D(filters=256, strides=2),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=1024, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(units=100, activation='softmax'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uwLRLqfRGeG",
        "colab_type": "code",
        "outputId": "07e74ea4-676b-422c-d885-25cd8ec1cacd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=[X_val, y_val])\n",
        "score = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:10] \n",
        "y_pred = model.predict(X_new)\n",
        "#print the 5 best predictions (best on the right) along the true class num\n",
        "for pred, true_label in zip(np.argsort(y_pred, axis=1)[:, -5:], y_test[:10]):#axis=0 along col, axis=1->line\n",
        "  print(pred, true_label, \"\\t\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 128)       6272      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              16778240  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               102500    \n",
            "=================================================================\n",
            "Total params: 18,509,924\n",
            "Trainable params: 18,509,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "45000/45000 [==============================] - 30s 666us/sample - loss: 3.9375 - accuracy: 0.1086 - val_loss: 3.4322 - val_accuracy: 0.1992\n",
            "Epoch 2/10\n",
            "45000/45000 [==============================] - 23s 509us/sample - loss: 3.2661 - accuracy: 0.2220 - val_loss: 3.0410 - val_accuracy: 0.2636\n",
            "Epoch 3/10\n",
            "45000/45000 [==============================] - 23s 507us/sample - loss: 2.8501 - accuracy: 0.2996 - val_loss: 2.8647 - val_accuracy: 0.3032\n",
            "Epoch 4/10\n",
            "45000/45000 [==============================] - 23s 508us/sample - loss: 2.5264 - accuracy: 0.3650 - val_loss: 2.8384 - val_accuracy: 0.3360\n",
            "Epoch 5/10\n",
            "45000/45000 [==============================] - 23s 508us/sample - loss: 2.2715 - accuracy: 0.4203 - val_loss: 2.5628 - val_accuracy: 0.3728\n",
            "Epoch 6/10\n",
            "45000/45000 [==============================] - 23s 507us/sample - loss: 2.0606 - accuracy: 0.4680 - val_loss: 2.3904 - val_accuracy: 0.3994\n",
            "Epoch 7/10\n",
            "45000/45000 [==============================] - 23s 511us/sample - loss: 1.8972 - accuracy: 0.5068 - val_loss: 2.3323 - val_accuracy: 0.4112\n",
            "Epoch 8/10\n",
            "45000/45000 [==============================] - 23s 508us/sample - loss: 1.7665 - accuracy: 0.5382 - val_loss: 2.3101 - val_accuracy: 0.4280\n",
            "Epoch 9/10\n",
            "45000/45000 [==============================] - 23s 507us/sample - loss: 1.6653 - accuracy: 0.5663 - val_loss: 2.3454 - val_accuracy: 0.4268\n",
            "Epoch 10/10\n",
            "45000/45000 [==============================] - 23s 507us/sample - loss: 1.5858 - accuracy: 0.5872 - val_loss: 2.2428 - val_accuracy: 0.4446\n",
            "10000/10000 [==============================] - 2s 169us/sample - loss: 2.2038 - accuracy: 0.4564\n",
            "[72 79 12 95 30] [49] \t\n",
            "[80 33 42 38 97] [33] \t\n",
            "[ 6 72 55 30  4] [72] \t\n",
            "[72 81 22 58 13] [51] \t\n",
            "[76 23 49 60 71] [71] \t\n",
            "[80 79  4 74  6] [92] \t\n",
            "[66 65 80 38 97] [15] \t\n",
            "[63 64 21 74 75] [14] \t\n",
            "[67 73 49 71 23] [23] \t\n",
            "[82 53  0 83 57] [0] \t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fj0mkevk1Xc",
        "colab_type": "text"
      },
      "source": [
        "accuracy : 0.62 val_accuracy : 0.44 (only). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovmAQGyjRLl-",
        "colab_type": "text"
      },
      "source": [
        "<h1>Pretrained model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y75WOaPfWhXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train = [print(x) for x in X_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCWIYLjlSZ61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f62bd07a-03f8-485f-f28d-df01dc162b01"
      },
      "source": [
        "n_classes =100\n",
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
        "                                                  include_top=False)\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=output)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPvs6SvXSaf0",
        "colab_type": "code",
        "outputId": "626621d1-edb9-42ff-e941-566518d04723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index, layer in enumerate(base_model.layers):\n",
        "    print(index, layer.name)\n",
        "#base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_5\n",
            "1 block1_conv1\n",
            "2 block1_conv1_bn\n",
            "3 block1_conv1_act\n",
            "4 block1_conv2\n",
            "5 block1_conv2_bn\n",
            "6 block1_conv2_act\n",
            "7 block2_sepconv1\n",
            "8 block2_sepconv1_bn\n",
            "9 block2_sepconv2_act\n",
            "10 block2_sepconv2\n",
            "11 block2_sepconv2_bn\n",
            "12 conv2d_16\n",
            "13 block2_pool\n",
            "14 batch_normalization_16\n",
            "15 add_48\n",
            "16 block3_sepconv1_act\n",
            "17 block3_sepconv1\n",
            "18 block3_sepconv1_bn\n",
            "19 block3_sepconv2_act\n",
            "20 block3_sepconv2\n",
            "21 block3_sepconv2_bn\n",
            "22 conv2d_17\n",
            "23 block3_pool\n",
            "24 batch_normalization_17\n",
            "25 add_49\n",
            "26 block4_sepconv1_act\n",
            "27 block4_sepconv1\n",
            "28 block4_sepconv1_bn\n",
            "29 block4_sepconv2_act\n",
            "30 block4_sepconv2\n",
            "31 block4_sepconv2_bn\n",
            "32 conv2d_18\n",
            "33 block4_pool\n",
            "34 batch_normalization_18\n",
            "35 add_50\n",
            "36 block5_sepconv1_act\n",
            "37 block5_sepconv1\n",
            "38 block5_sepconv1_bn\n",
            "39 block5_sepconv2_act\n",
            "40 block5_sepconv2\n",
            "41 block5_sepconv2_bn\n",
            "42 block5_sepconv3_act\n",
            "43 block5_sepconv3\n",
            "44 block5_sepconv3_bn\n",
            "45 add_51\n",
            "46 block6_sepconv1_act\n",
            "47 block6_sepconv1\n",
            "48 block6_sepconv1_bn\n",
            "49 block6_sepconv2_act\n",
            "50 block6_sepconv2\n",
            "51 block6_sepconv2_bn\n",
            "52 block6_sepconv3_act\n",
            "53 block6_sepconv3\n",
            "54 block6_sepconv3_bn\n",
            "55 add_52\n",
            "56 block7_sepconv1_act\n",
            "57 block7_sepconv1\n",
            "58 block7_sepconv1_bn\n",
            "59 block7_sepconv2_act\n",
            "60 block7_sepconv2\n",
            "61 block7_sepconv2_bn\n",
            "62 block7_sepconv3_act\n",
            "63 block7_sepconv3\n",
            "64 block7_sepconv3_bn\n",
            "65 add_53\n",
            "66 block8_sepconv1_act\n",
            "67 block8_sepconv1\n",
            "68 block8_sepconv1_bn\n",
            "69 block8_sepconv2_act\n",
            "70 block8_sepconv2\n",
            "71 block8_sepconv2_bn\n",
            "72 block8_sepconv3_act\n",
            "73 block8_sepconv3\n",
            "74 block8_sepconv3_bn\n",
            "75 add_54\n",
            "76 block9_sepconv1_act\n",
            "77 block9_sepconv1\n",
            "78 block9_sepconv1_bn\n",
            "79 block9_sepconv2_act\n",
            "80 block9_sepconv2\n",
            "81 block9_sepconv2_bn\n",
            "82 block9_sepconv3_act\n",
            "83 block9_sepconv3\n",
            "84 block9_sepconv3_bn\n",
            "85 add_55\n",
            "86 block10_sepconv1_act\n",
            "87 block10_sepconv1\n",
            "88 block10_sepconv1_bn\n",
            "89 block10_sepconv2_act\n",
            "90 block10_sepconv2\n",
            "91 block10_sepconv2_bn\n",
            "92 block10_sepconv3_act\n",
            "93 block10_sepconv3\n",
            "94 block10_sepconv3_bn\n",
            "95 add_56\n",
            "96 block11_sepconv1_act\n",
            "97 block11_sepconv1\n",
            "98 block11_sepconv1_bn\n",
            "99 block11_sepconv2_act\n",
            "100 block11_sepconv2\n",
            "101 block11_sepconv2_bn\n",
            "102 block11_sepconv3_act\n",
            "103 block11_sepconv3\n",
            "104 block11_sepconv3_bn\n",
            "105 add_57\n",
            "106 block12_sepconv1_act\n",
            "107 block12_sepconv1\n",
            "108 block12_sepconv1_bn\n",
            "109 block12_sepconv2_act\n",
            "110 block12_sepconv2\n",
            "111 block12_sepconv2_bn\n",
            "112 block12_sepconv3_act\n",
            "113 block12_sepconv3\n",
            "114 block12_sepconv3_bn\n",
            "115 add_58\n",
            "116 block13_sepconv1_act\n",
            "117 block13_sepconv1\n",
            "118 block13_sepconv1_bn\n",
            "119 block13_sepconv2_act\n",
            "120 block13_sepconv2\n",
            "121 block13_sepconv2_bn\n",
            "122 conv2d_19\n",
            "123 block13_pool\n",
            "124 batch_normalization_19\n",
            "125 add_59\n",
            "126 block14_sepconv1\n",
            "127 block14_sepconv1_bn\n",
            "128 block14_sepconv1_act\n",
            "129 block14_sepconv2\n",
            "130 block14_sepconv2_bn\n",
            "131 block14_sepconv2_act\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azIXvmQK5D0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "X_train_resized = np.zeros((45000,224, 224, 3))\n",
        "X_val_resized = np.zeros((5000,224, 224, 3))\n",
        "X_test_resized = np.zeros((10000,224, 224, 3))\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  X_train_resized[i] = resize(X_train[i], (224, 224))\n",
        "for i in range(len(X_val)):\n",
        "  X_val_resized[i] = resize(X_val[i], (224, 224))\n",
        "for i in range(len(X_train)):\n",
        "  X_test_resized[i] = resize(X_test[i], (224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2y8IaFBSwwc",
        "colab_type": "code",
        "outputId": "56086564-a865-4b5c-93a6-cd2339791875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "source": [
        "#freeze every pretrained layer and fit only the last dense layer for output\n",
        "batch_size=32\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    steps_per_epoch=int(X_train_resized.shape[0]/batch_size),\n",
        "                    validation_steps= int(X_val_resized.shape[0]/batch_size),\n",
        "                    validation_data=[X_val_resized, y_val],\n",
        "                    epochs=5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 1406.25 steps, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "1407/1406 [==============================] - 38s 27ms/step - loss: 4.5537 - accuracy: 0.0349 - val_loss: 4.5802 - val_accuracy: 0.0146\n",
            "Epoch 2/100\n",
            "1407/1406 [==============================] - 35s 25ms/step - loss: 4.5360 - accuracy: 0.0397 - val_loss: 4.5778 - val_accuracy: 0.0184\n",
            "Epoch 3/100\n",
            "1407/1406 [==============================] - 35s 25ms/step - loss: 4.5294 - accuracy: 0.0406 - val_loss: 4.5753 - val_accuracy: 0.0162\n",
            "Epoch 4/100\n",
            "1407/1406 [==============================] - 35s 25ms/step - loss: 4.5253 - accuracy: 0.0396 - val_loss: 4.5769 - val_accuracy: 0.0182\n",
            "Epoch 5/100\n",
            "1407/1406 [==============================] - 35s 25ms/step - loss: 4.5234 - accuracy: 0.0438 - val_loss: 4.5749 - val_accuracy: 0.0192\n",
            "Epoch 6/100\n",
            "1407/1406 [==============================] - 35s 25ms/step - loss: 4.5192 - accuracy: 0.0432 - val_loss: 4.5728 - val_accuracy: 0.0180\n",
            "Epoch 7/100\n",
            "1072/1406 [=====================>........] - ETA: 7s - loss: 4.5115 - accuracy: 0.0445"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-237c8993c7fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     epochs=100)\n\u001b[0m\u001b[1;32m     12\u001b[0m \"\"\"\n\u001b[1;32m     13\u001b[0m history = model.fit(X_train, y_train,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idu7gFWfS1ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#then fit the rest with a very smal learning rate so the CNN so we don't break everthing.\n",
        "#High lr would result in high change in the weights and bias of the Xception base model)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n",
        "                                 nesterov=True, decay=0.001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    steps_per_epoch=int(X_train_resized.shape[0]/batch_size),\n",
        "                    validation_steps= int(X_val_resized.shape[0]/batch_size),\n",
        "                    validation_data=[X_val_resized, y_val],\n",
        "                    epochs=50)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}